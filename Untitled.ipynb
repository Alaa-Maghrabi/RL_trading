{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b5569f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0a81966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitcoinTradingEnv(gym.Env):\n",
    "    \"\"\"A Bitcoin trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['live', 'file', 'none']}\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    viewer = None\n",
    "\n",
    "    def __init__(self, df, lookback_window_size=50, \n",
    "                             commission=0.00075,  \n",
    "                             initial_balance=10000,\n",
    "                             serial=False):\n",
    "        super(BitcoinTradingEnv, self).__init__()\n",
    "\n",
    "        self.df = df.dropna().reset_index()\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.commission = commission\n",
    "        self.serial = serial\n",
    "\n",
    "        # Actions of the format Buy 1/10, Sell 3/10, Hold, etc.\n",
    "        self.action_space = spaces.MultiDiscrete([3, 10])\n",
    "\n",
    "        # Observes the OHCLV values, net worth, and trade history\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(10, \n",
    "                        lookback_window_size + 1), dtype=np.float16)\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.btc_held = 0\n",
    "\n",
    "        self._reset_session()\n",
    "\n",
    "        self.account_history = np.repeat([\n",
    "        [self.net_worth],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0]\n",
    "              ], self.lookback_window_size + 1, axis=1)\n",
    "\n",
    "        self.trades = []\n",
    "\n",
    "        return self._next_observation()\n",
    "    \n",
    "    def _reset_session(self):\n",
    "        self.current_step = 0\n",
    "\n",
    "        if self.serial:\n",
    "            self.steps_left = len(self.df) - self.lookback_window_size - 1\n",
    "            self.frame_start = self.lookback_window_size\n",
    "        else:\n",
    "            self.steps_left = np.random.randint(1, MAX_TRADING_SESSION)\n",
    "            self.frame_start = np.random.randint(\n",
    "                 self.lookback_window_size, len(self.df) - self.steps_left)\n",
    "\n",
    "        self.active_df = self.df[self.frame_start -   \n",
    "           self.lookback_window_size:self.frame_start + self.steps_left]\n",
    "\n",
    "    def _next_observation(self):\n",
    "        end = self.current_step + self.lookback_window_size + 1\n",
    "\n",
    "        obs = np.array([\n",
    "        self.active_df['Open'].values[self.current_step:end],  \n",
    "        self.active_df['High'].values[self.current_step:end],\n",
    "        self.active_df['Low'].values[self.current_step:end],\n",
    "        self.active_df['Close'].values[self.current_step:end],\n",
    "        self.active_df['Volume_(BTC)'].values[self.current_step:end],\n",
    "        ])\n",
    "\n",
    "        scaled_history = self.scaler.fit_transform(self.account_history)\n",
    "\n",
    "        obs = np.append(obs, scaled_history[:, -(self.lookback_window_size\n",
    "                                                 + 1):], axis=0)\n",
    "\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        current_price = self._get_current_price() + 0.01\n",
    "        self._take_action(action, current_price)\n",
    "        self.steps_left -= 1\n",
    "        self.current_step += 1\n",
    "\n",
    "        if self.steps_left == 0:\n",
    "            self.balance += self.btc_held * current_price\n",
    "            self.btc_held = 0\n",
    "            self._reset_session()\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        reward = self.net_worth\n",
    "        done = self.net_worth <= 0\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def _take_action(self, action, current_price):\n",
    "        action_type = action[0]\n",
    "        amount = action[1] / 10\n",
    "        btc_bought = 0\n",
    "        btc_sold = 0\n",
    "        cost = 0\n",
    "        sales = 0\n",
    "\n",
    "        if action_type < 1:\n",
    "            btc_bought = self.balance / current_price * amount\n",
    "            cost = btc_bought * current_price * (1 + self.commission)\n",
    "            self.btc_held += btc_bought\n",
    "            self.balance -= cost\n",
    "\n",
    "        elif action_type < 2:\n",
    "            btc_sold = self.btc_held * amount\n",
    "            sales = btc_sold * current_price  * (1 - self.commission)\n",
    "            self.btc_held -= btc_sold\n",
    "            self.balance += sales\n",
    "            \n",
    "        if btc_sold > 0 or btc_bought > 0:\n",
    "            self.trades.append({\n",
    "              'step': self.frame_start+self.current_step,\n",
    "              'amount': btc_sold if btc_sold > 0 else btc_bought,\n",
    "              'total': sales if btc_sold > 0 else cost,\n",
    "              'type': \"sell\" if btc_sold > 0 else \"buy\"\n",
    "            })\n",
    "\n",
    "        self.net_worth = self.balance + self.btc_held * current_price\n",
    "        self.account_history = np.append(self.account_history, [\n",
    "            [self.net_worth],\n",
    "            [btc_bought],\n",
    "            [cost],\n",
    "            [btc_sold],\n",
    "            [sales]\n",
    "            ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f6313b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.reward_range = (0, MAX_ACCOUNT_BALANCE) \n",
    "        # Actions of the format Buy x%, Sell x%, Hold, etc.\n",
    "        self.action_space = spaces.Box(\n",
    "          low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float16)\n",
    "        # Prices contains the OHCL values for the last five prices\n",
    "        self.observation_space = spaces.Box(\n",
    "          low=0, high=1, shape=(6, 6), dtype=np.float16)\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
    "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
    "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
    "        self.shares_held = 0\n",
    "        self.cost_basis = 0\n",
    "        self.total_shares_sold = 0\n",
    "        self.total_sales_value = 0\n",
    "\n",
    "        # Set the current step to a random point within the data frame\n",
    "        self.current_step = random.randint(0, len(self.df.loc[:, 'Open'].values) - 6)\n",
    "        return self._next_observation()\n",
    "    \n",
    "    def _next_observation(self):\n",
    "        # Get the data points for the last 5 days and scale to between 0-1\n",
    "        frame = np.array([\n",
    "            self.df.loc[self.current_step: self.current_step +\n",
    "                        5, 'Open'].values / MAX_SHARE_PRICE,\n",
    "            self.df.loc[self.current_step: self.current_step +\n",
    "                        5, 'High'].values / MAX_SHARE_PRICE,\n",
    "            self.df.loc[self.current_step: self.current_step +\n",
    "                        5, 'Low'].values / MAX_SHARE_PRICE,\n",
    "            self.df.loc[self.current_step: self.current_step +\n",
    "                        5, 'Close'].values / MAX_SHARE_PRICE,\n",
    "            self.df.loc[self.current_step: self.current_step +\n",
    "                        5, 'Volume'].values / MAX_NUM_SHARES,\n",
    "            ])\n",
    "        \n",
    "        # Append additional data and scale each value to between 0-1\n",
    "        obs = np.append(frame, [[\n",
    "            self.balance / MAX_ACCOUNT_BALANCE,\n",
    "            self.max_net_worth / MAX_ACCOUNT_BALANCE,\n",
    "            self.shares_held / MAX_NUM_SHARES,\n",
    "            self.cost_basis / MAX_SHARE_PRICE,\n",
    "            self.total_shares_sold / MAX_NUM_SHARES,\n",
    "            self.total_sales_value / (MAX_NUM_SHARES * MAX_SHARE_PRICE),\n",
    "            ]], axis=0)\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        self._take_action(action)\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step > len(self.df.loc[:, 'Open'].values) - 6:\n",
    "            self.current_step = 0\n",
    "        \n",
    "        delay_modifier = (self.current_step / MAX_STEPS)\n",
    "\n",
    "        reward = self.balance * delay_modifier\n",
    "        done = self.net_worth <= 0\n",
    "        \n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        # Set the current price to a random price within the time step\n",
    "        current_price = random.uniform(self.df.loc[self.current_step, \"Open\"],\n",
    "                                       self.df.loc[self.current_step, \"Close\"])\n",
    "\n",
    "        action_type = action[0]\n",
    "        amount = action[1]\n",
    "\n",
    "        if action_type < 1:\n",
    "            # Buy amount % of balance in shares\n",
    "            total_possible = self.balance / current_price\n",
    "            shares_bought = total_possible * amount\n",
    "            prev_cost = self.cost_basis * self.shares_held\n",
    "            additional_cost = shares_bought * current_price\n",
    "            self.balance -= additional_cost\n",
    "            self.cost_basis = (prev_cost + additional_cost) / (self.shares_held + shares_bought)\n",
    "            self.shares_held += shares_bought\n",
    "        elif action_type < 2:\n",
    "            # Sell amount % of shares held\n",
    "            shares_sold = self.shares_held * amount \n",
    "            self.balance += shares_sold * current_price\n",
    "            self.shares_held -= shares_sold\n",
    "            self.total_shares_sold += shares_sold\n",
    "            self.total_sales_value += shares_sold * current_price\n",
    "\n",
    "        self.netWorth = self.balance + self.shares_held * current_price\n",
    "\n",
    "        if self.net_worth > self.max_net_worth:\n",
    "            self.max_net_worth = self.net_worth\n",
    "\n",
    "        if self.shares_held == 0:\n",
    "            self.cost_basis = 0\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        profit = self.net_worth - INITIAL_ACCOUNT_BALANCE\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Balance: {self.balance}')\n",
    "        print(f'Shares held: {self.shares_held} (Total sold: {self.total_shares_sold})')\n",
    "        print(f'Avg cost for held shares: {self.cost_basis} (Total sales value: {self.total_sales_value})')\n",
    "        print(f'Net worth: {self.net_worth} (Max net worth: {self.max_net_worth})')\n",
    "        print(f'Profit: {profit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e99ccf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\programdata\\anaconda3\\envs\\rl\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m(1443)\u001b[0;36m_call_tf_sessionrun\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   1441 \u001b[1;33m    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[0m\u001b[1;32m   1442 \u001b[1;33m                                            \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 1443 \u001b[1;33m                                            run_metadata)\n",
      "\u001b[0m\u001b[1;32m   1444 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1445 \u001b[1;33m  \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\ipykernel_launcher.py:90: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 1.31851765e-08 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 342            |\n",
      "| n_updates          | 1              |\n",
      "| policy_entropy     | 2.837864       |\n",
      "| policy_loss        | -1.5216414e-05 |\n",
      "| serial_timesteps   | 128            |\n",
      "| time_elapsed       | 0              |\n",
      "| total_timesteps    | 128            |\n",
      "| value_loss         | 47914148.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.4189742e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 822            |\n",
      "| n_updates          | 2              |\n",
      "| policy_entropy     | 2.8378885      |\n",
      "| policy_loss        | -1.8379651e-05 |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 0.375          |\n",
      "| total_timesteps    | 256            |\n",
      "| value_loss         | 46588320.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.965031e-08   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 838            |\n",
      "| n_updates          | 3              |\n",
      "| policy_entropy     | 2.8381376      |\n",
      "| policy_loss        | -7.2976574e-05 |\n",
      "| serial_timesteps   | 384            |\n",
      "| time_elapsed       | 0.531          |\n",
      "| total_timesteps    | 384            |\n",
      "| value_loss         | 53074370.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5378944e-07  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 807            |\n",
      "| n_updates          | 4              |\n",
      "| policy_entropy     | 2.8386905      |\n",
      "| policy_loss        | -0.00014973478 |\n",
      "| serial_timesteps   | 512            |\n",
      "| time_elapsed       | 0.685          |\n",
      "| total_timesteps    | 512            |\n",
      "| value_loss         | 26166882.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7349458e-07  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 815            |\n",
      "| n_updates          | 5              |\n",
      "| policy_entropy     | 2.8393154      |\n",
      "| policy_loss        | -3.2938085e-05 |\n",
      "| serial_timesteps   | 640            |\n",
      "| time_elapsed       | 0.844          |\n",
      "| total_timesteps    | 640            |\n",
      "| value_loss         | 68388390.0     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.216925e-08  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 797           |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 2.8398743     |\n",
      "| policy_loss        | 2.2512395e-06 |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 1             |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 15114596.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5849197e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 797            |\n",
      "| n_updates          | 7              |\n",
      "| policy_entropy     | 2.84144        |\n",
      "| policy_loss        | -0.00017951813 |\n",
      "| serial_timesteps   | 896            |\n",
      "| time_elapsed       | 1.16           |\n",
      "| total_timesteps    | 896            |\n",
      "| value_loss         | 49654220.0     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.5288983e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 810            |\n",
      "| n_updates          | 8              |\n",
      "| policy_entropy     | 2.8434522      |\n",
      "| policy_loss        | -8.1007136e-05 |\n",
      "| serial_timesteps   | 1024           |\n",
      "| time_elapsed       | 1.33           |\n",
      "| total_timesteps    | 1024           |\n",
      "| value_loss         | 59171344.0     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 5.92182e-06  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 815          |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 2.8441837    |\n",
      "| policy_loss        | 0.0002110072 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 1.48         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 13463159.0   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8743798e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 797            |\n",
      "| n_updates          | 10             |\n",
      "| policy_entropy     | 2.845792       |\n",
      "| policy_loss        | -0.00046623254 |\n",
      "| serial_timesteps   | 1280           |\n",
      "| time_elapsed       | 1.64           |\n",
      "| total_timesteps    | 1280           |\n",
      "| value_loss         | 84132460.0     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0041108e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 791           |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 2.847962      |\n",
      "| policy_loss        | -6.220979e-05 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 1.8           |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 78013080.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.854699e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 780            |\n",
      "| n_updates          | 12             |\n",
      "| policy_entropy     | 2.8498178      |\n",
      "| policy_loss        | -0.00014393497 |\n",
      "| serial_timesteps   | 1536           |\n",
      "| time_elapsed       | 1.97           |\n",
      "| total_timesteps    | 1536           |\n",
      "| value_loss         | 55734824.0     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.402061e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 783           |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 2.8522685     |\n",
      "| policy_loss        | -0.0006215193 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 2.13          |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 96177300.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.6527734e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 786           |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 2.8552885     |\n",
      "| policy_loss        | -0.0004604461 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 2.3           |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 14657811.0    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.066628e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 809            |\n",
      "| n_updates          | 15             |\n",
      "| policy_entropy     | 2.8593483      |\n",
      "| policy_loss        | -0.00013184501 |\n",
      "| serial_timesteps   | 1920           |\n",
      "| time_elapsed       | 2.46           |\n",
      "| total_timesteps    | 1920           |\n",
      "| value_loss         | 173336430.0    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.6435872e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 778           |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 2.8606324     |\n",
      "| policy_loss        | -0.0004950105 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 2.62          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 95851540.0    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 5.3632408e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 781           |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 2.8624165     |\n",
      "| policy_loss        | -0.0025192956 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 2.78          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 45239730.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000241394   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 792           |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 2.863509      |\n",
      "| policy_loss        | -0.0010682138 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 2.95          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 37890948.0    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010120269 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 813           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 2.8656416     |\n",
      "| policy_loss        | -0.0014547023 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 3.11          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 107905600.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016481684 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 779           |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 2.8673224     |\n",
      "| policy_loss        | -0.0003808352 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 3.27          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 215311470.0   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.499193e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 798            |\n",
      "| n_updates          | 21             |\n",
      "| policy_entropy     | 2.8687139      |\n",
      "| policy_loss        | -0.00034300424 |\n",
      "| serial_timesteps   | 2688           |\n",
      "| time_elapsed       | 3.43           |\n",
      "| total_timesteps    | 2688           |\n",
      "| value_loss         | 35646340.0     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 6.000401e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 813          |\n",
      "| n_updates          | 22           |\n",
      "| policy_entropy     | 2.8695517    |\n",
      "| policy_loss        | 0.0011454334 |\n",
      "| serial_timesteps   | 2816         |\n",
      "| time_elapsed       | 3.6          |\n",
      "| total_timesteps    | 2816         |\n",
      "| value_loss         | 132782280.0  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.057681e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 821            |\n",
      "| n_updates          | 23             |\n",
      "| policy_entropy     | 2.8711705      |\n",
      "| policy_loss        | -0.00031728763 |\n",
      "| serial_timesteps   | 2944           |\n",
      "| time_elapsed       | 3.75           |\n",
      "| total_timesteps    | 2944           |\n",
      "| value_loss         | 71108910.0     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037859386 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 811           |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 2.8740964     |\n",
      "| policy_loss        | -0.0014955206 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 3.91          |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 273262140.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00050938106 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 809           |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 2.8759558     |\n",
      "| policy_loss        | -0.0074017765 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 4.07          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 114391096.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0029537394 |\n",
      "| clipfrac           | 0.03125      |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 736          |\n",
      "| n_updates          | 26           |\n",
      "| policy_entropy     | 2.8772657    |\n",
      "| policy_loss        | -0.013910139 |\n",
      "| serial_timesteps   | 3328         |\n",
      "| time_elapsed       | 4.23         |\n",
      "| total_timesteps    | 3328         |\n",
      "| value_loss         | 395922700.0  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016722698  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 778           |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 2.8780372     |\n",
      "| policy_loss        | -0.0011971663 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 4.4           |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 190905540.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.921624e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 807           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 2.8784177     |\n",
      "| policy_loss        | 0.00042568007 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 4.57          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 206596800.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.4163964e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 797           |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 2.8776588     |\n",
      "| policy_loss        | 0.0010783979  |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 4.73          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 403110560.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006622547 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 828          |\n",
      "| n_updates          | 30           |\n",
      "| policy_entropy     | 2.878971     |\n",
      "| policy_loss        | 0.002057325  |\n",
      "| serial_timesteps   | 3840         |\n",
      "| time_elapsed       | 4.89         |\n",
      "| total_timesteps    | 3840         |\n",
      "| value_loss         | 219138830.0  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023575831 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 763           |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 2.879568      |\n",
      "| policy_loss        | 0.0009351487  |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 5.05          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 363262700.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00053306686 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 773           |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 2.8804986     |\n",
      "| policy_loss        | -0.003294422  |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 5.21          |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 659033150.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001138979  |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 797          |\n",
      "| n_updates          | 33           |\n",
      "| policy_entropy     | 2.8832703    |\n",
      "| policy_loss        | -0.002713428 |\n",
      "| serial_timesteps   | 4224         |\n",
      "| time_elapsed       | 5.38         |\n",
      "| total_timesteps    | 4224         |\n",
      "| value_loss         | 982101800.0  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0011416039  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 798           |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 2.8855917     |\n",
      "| policy_loss        | -0.0048526246 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 5.54          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 568909000.0   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0033661106 |\n",
      "| clipfrac           | 0.03515625   |\n",
      "| explained_variance | -1.19e-07    |\n",
      "| fps                | 820          |\n",
      "| n_updates          | 35           |\n",
      "| policy_entropy     | 2.8873675    |\n",
      "| policy_loss        | -0.012520377 |\n",
      "| serial_timesteps   | 4480         |\n",
      "| time_elapsed       | 5.71         |\n",
      "| total_timesteps    | 4480         |\n",
      "| value_loss         | 452450430.0  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014662986 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 765          |\n",
      "| n_updates          | 36           |\n",
      "| policy_entropy     | 2.8894434    |\n",
      "| policy_loss        | 0.005239509  |\n",
      "| serial_timesteps   | 4608         |\n",
      "| time_elapsed       | 5.86         |\n",
      "| total_timesteps    | 4608         |\n",
      "| value_loss         | 834802370.0  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00014509342  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.19e-07      |\n",
      "| fps                | 804            |\n",
      "| n_updates          | 37             |\n",
      "| policy_entropy     | 2.8892164      |\n",
      "| policy_loss        | -0.00070473645 |\n",
      "| serial_timesteps   | 4736           |\n",
      "| time_elapsed       | 6.03           |\n",
      "| total_timesteps    | 4736           |\n",
      "| value_loss         | 835702140.0    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039417943 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 807           |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 2.887545      |\n",
      "| policy_loss        | -0.001462145  |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 6.19          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 1154982500.0  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010558334  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 807           |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 2.8862185     |\n",
      "| policy_loss        | -0.0074595977 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 6.35          |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 792892200.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0031780154  |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 807           |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 2.8869777     |\n",
      "| policy_loss        | -0.0033245976 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 6.51          |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 971691300.0   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006971061  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 799           |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 2.8884835     |\n",
      "| policy_loss        | -0.0016187162 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 6.67          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 1141635600.0  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00071944506 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 802           |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 2.8872087     |\n",
      "| policy_loss        | 0.0037676215  |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 6.83          |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 2211839200.0  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017495372 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 813           |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 2.8855312     |\n",
      "| policy_loss        | 0.0014032058  |\n",
      "| serial_timesteps   | 5504          |\n",
      "| time_elapsed       | 6.99          |\n",
      "| total_timesteps    | 5504          |\n",
      "| value_loss         | 1445590800.0  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028637267 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 784           |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 2.8843024     |\n",
      "| policy_loss        | -0.0006663407 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 7.15          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 1086878700.0  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001696632  |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 793          |\n",
      "| n_updates          | 45           |\n",
      "| policy_entropy     | 2.8834815    |\n",
      "| policy_loss        | -0.008158531 |\n",
      "| serial_timesteps   | 5760         |\n",
      "| time_elapsed       | 7.31         |\n",
      "| total_timesteps    | 5760         |\n",
      "| value_loss         | 1783086200.0 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-bd254cf0b152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMlpPolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_rollout_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;31m# true_reward is the reward without discount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                 \u001b[0mrollout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m                 \u001b[1;31m# Unpack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines\\common\\runners.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, callback)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_rews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# save final observation where user can get it, then reset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-07d33e9062de>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_worth\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_observation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-07d33e9062de>\u001b[0m in \u001b[0;36m_next_observation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m                         5, 'Close'].values / MAX_SHARE_PRICE,\n\u001b[0;32m     41\u001b[0m             self.df.loc[self.current_step: self.current_step +\n\u001b[1;32m---> 42\u001b[1;33m                         5, 'Volume'].values / MAX_NUM_SHARES,\n\u001b[0m\u001b[0;32m     43\u001b[0m             ])\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%debug\n",
    "df = pd.read_csv('EURUSD60.csv', delimiter='\\t',\n",
    "                       names=['Date','Open','High','Low','Close','Volume'])\n",
    "\n",
    "# df = pd.read_csv('AAPL.csv')\n",
    "# df = df.sort_values('Date')\n",
    "\n",
    "MAX_ACCOUNT_BALANCE = 2147483647\n",
    "INITIAL_ACCOUNT_BALANCE = 10000\n",
    "MAX_NUM_SHARES = 2147483647\n",
    "MAX_SHARE_PRICE = 5000\n",
    "MAX_OPEN_POSITIONS = 5\n",
    "MAX_STEPS = 20000\n",
    "\n",
    "# The algorithms require a vectorized environment to run\n",
    "env = DummyVecEnv([lambda: StockTradingEnv(df)])\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=20000)\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(2000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
